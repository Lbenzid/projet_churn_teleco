# PrÃ©diction du Churn - TÃ©lÃ©communications

Ce projet a pour objectif d'analyser et de prÃ©dire le dÃ©sabonnement des clients d'une entreprise de tÃ©lÃ©communications (churn). Il a Ã©tÃ© menÃ© entiÃ¨rement sous VS Code en scripts Python, dans une dÃ©marche rigoureuse de data science appliquÃ©e.

---

##  Structure du projet
projet_churn_telco/
â”œâ”€â”€ data/                # DonnÃ©es brutes ou nettoyÃ©es (ex : WA_Fn-UseC_-Telco-Customer-Churn.csv)
â”œâ”€â”€ models/              # (Ã€ venir) Sauvegarde des modÃ¨les entraÃ®nÃ©s
â”œâ”€â”€ notebooks/           # Contient le script EDA et preprocessing (au format .ipynb pour initialisation rapide)
â”œâ”€â”€ src/                 # (Ã€ venir) Fonctions rÃ©utilisables ou modules Python
â”œâ”€â”€ requirements.txt     # Librairies Python nÃ©cessaires
â””â”€â”€ README.md            # Documentation du projet


## Objectifs

- Identifier les variables influentes sur le churn client Ã  partir des donnÃ©es disponibles.
- RÃ©aliser une analyse exploratoire (EDA) approfondie.
- PrÃ©parer les donnÃ©es pour une future modÃ©lisation (encodage, traitement des valeurs manquantes, etc.).
- Mettre en place un pipeline reproductible via des scripts dans un environnement structurÃ©.

## Ã‰tapes rÃ©alisÃ©es

- **Chargement et nettoyage des donnÃ©es**
- **Analyse exploratoire (EDA)** :
  - CorrÃ©lation entre les variables et la variable cible (`Churn`)
  - Statistiques descriptives et visualisation des distributions
- **Encodage** :
  - Transformation des variables catÃ©gorielles par `get_dummies` (one-hot encoding)
- **CrÃ©ation dâ€™un environnement de travail modulaire** avec :
  - `requirements.txt`
  - `README.md` documentÃ©
  - Arborescence propre pour Ã©voluer vers la modÃ©lisation

## Prochaines Ã©tapes

- ImplÃ©mentation des modÃ¨les prÃ©dictifs (Logistic Regression, Random Forest, etc.)
- Ã‰valuation des performances (Accuracy, Recall, AUC, etc.)
- Export des modÃ¨les et automatisation du pipeline

## ğŸ’¡ Auteur

Projet rÃ©alisÃ© par **Lilia Benzid** â€“ Data Scientist junior, passionnÃ©e par la data et lâ€™IA appliquÃ©e.
